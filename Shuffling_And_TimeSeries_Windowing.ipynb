{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Shuffling And TimeSeries Windowing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "w43XcnKcdd2U"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pathlib\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBWdAo5HdlLm"
      },
      "source": [
        "#shuffling the data prevents from learning spurious patterns in the training data. \n",
        "#This also improves the convergence of gradient based methods, such as training a neural network using Gradient Descent. To shuffle the data, use the shuffle() method"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "671KO_JxfR8v",
        "outputId": "d892f924-6a3a-40e4-e49f-89c2280d384f"
      },
      "source": [
        "file_path = tf.keras.utils.get_file(\"train.csv\", \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
        "dataset = tf.data.TextLineDataset(file_path)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
            "32768/30874 [===============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLy8aJ4udpuF"
      },
      "source": [
        "data = tf.data.TextLineDataset(file_path)\n",
        "counter = tf.data.experimental.Counter()\n",
        "\n",
        "dataset = tf.data.Dataset.zip((counter, data))\n",
        "dataset = dataset.batch(20)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BkNEs6Idp_o",
        "outputId": "b5b7e7b3-4cf8-47b7-bc33-690a2827945b"
      },
      "source": [
        "n,line_batch = next(iter(dataset))\n",
        "print(n.numpy())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Snntxr_ffuRV",
        "outputId": "b4ccf5d5-fd8f-4a5e-82db-03c3b7cfb535"
      },
      "source": [
        "data = tf.data.TextLineDataset(file_path)\n",
        "counter = tf.data.experimental.Counter()\n",
        "\n",
        "dataset = tf.data.Dataset.zip((counter, data))\n",
        "dataset = dataset.shuffle(buffer_size=100)\n",
        "dataset = dataset.batch(20)\n",
        "dataset"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((None,), (None,)), types: (tf.int64, tf.string)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBUIEpW-f3gd",
        "outputId": "3cc0350b-4826-49b3-9ea4-b2358d37b178"
      },
      "source": [
        "n,line_batch = next(iter(dataset))\n",
        "print(n.numpy())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 69   7   5  10  52  84  63  70  92  25 107   0  35 110 103   2  86  48\n",
            "  80  68]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ALjwBPxf5fb"
      },
      "source": [
        "#time series windowing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "745QK4qsf5iv"
      },
      "source": [
        "ds = tf.data.Dataset.range(50)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sz7jJ9gf5rp",
        "outputId": "032909ed-f7da-4c4e-8e62-81859d48fcde"
      },
      "source": [
        "batches = ds.batch(10, drop_remainder=True)\n",
        "\n",
        "for batch in batches.take(5):\n",
        "  print(batch.numpy())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 5 6 7 8 9]\n",
            "[10 11 12 13 14 15 16 17 18 19]\n",
            "[20 21 22 23 24 25 26 27 28 29]\n",
            "[30 31 32 33 34 35 36 37 38 39]\n",
            "[40 41 42 43 44 45 46 47 48 49]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjLMXCVKnMnc",
        "outputId": "ae69c9cf-0f14-4879-dcba-20cdaf0aa801"
      },
      "source": [
        "def dense_1_step(batch):\n",
        "  return batch[:8], batch[3:]\n",
        "\n",
        "predict_dense_1_step = batches.map(dense_1_step)\n",
        "\n",
        "for features, label in predict_dense_1_step.take(3):\n",
        "  print(features.numpy(), \" => \", label.numpy())"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 5 6 7]  =>  [3 4 5 6 7 8 9]\n",
            "[10 11 12 13 14 15 16 17]  =>  [13 14 15 16 17 18 19]\n",
            "[20 21 22 23 24 25 26 27]  =>  [23 24 25 26 27 28 29]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnQOOOT5nMq5",
        "outputId": "65dcddc6-7d97-49e1-902b-ac6b0894c193"
      },
      "source": [
        "feature_length = 10\n",
        "label_length = 5\n",
        "\n",
        "features = ds.batch(feature_length, drop_remainder=True)\n",
        "labels = ds.batch(feature_length).skip(1).map(lambda labels: labels[:3])\n",
        "\n",
        "predict = tf.data.Dataset.zip((features, labels))\n",
        "\n",
        "for features, label in predict.take(5):\n",
        "  print(features.numpy(), \" => \", label.numpy())"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 5 6 7 8 9]  =>  [10 11 12]\n",
            "[10 11 12 13 14 15 16 17 18 19]  =>  [20 21 22]\n",
            "[20 21 22 23 24 25 26 27 28 29]  =>  [30 31 32]\n",
            "[30 31 32 33 34 35 36 37 38 39]  =>  [40 41 42]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0n9SNstp3qy",
        "outputId": "c9e3b419-c24b-4b21-e4f7-680f9623bedc"
      },
      "source": [
        "window_size = 10\n",
        "\n",
        "windows = ds.window(window_size, shift=1)\n",
        "for sub_ds in windows.take(5):\n",
        "  print(sub_ds)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<_VariantDataset shapes: (4,), types: tf.int64>\n",
            "<_VariantDataset shapes: (4,), types: tf.int64>\n",
            "<_VariantDataset shapes: (4,), types: tf.int64>\n",
            "<_VariantDataset shapes: (4,), types: tf.int64>\n",
            "<_VariantDataset shapes: (4,), types: tf.int64>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1s0n2DI2qD5b",
        "outputId": "3e2e1863-481e-4810-8097-10dd03a33004"
      },
      "source": [
        "for x in windows.flat_map(lambda x: x).take(20):\n",
        "   print(x.numpy(), end=' ')"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7f4a6b74a598> and will run it as-is.\n",
            "Cause: could not parse the source code:\n",
            "\n",
            "for x in windows.flat_map(lambda x: x).take(20):\n",
            "\n",
            "This error may be avoided by creating the lambda in a standalone statement.\n",
            "\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function <lambda> at 0x7f4a6b74a598> and will run it as-is.\n",
            "Cause: could not parse the source code:\n",
            "\n",
            "for x in windows.flat_map(lambda x: x).take(20):\n",
            "\n",
            "This error may be avoided by creating the lambda in a standalone statement.\n",
            "\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "[ 0  5 10 15] [20 25 30 35] [ 5 10 15 20] [25 30 35 40] [10 15 20 25] [30 35 40 45] [15 20 25 30] [20 25 30 35] [25 30 35 40] [30 35 40 45] [20 25 30 35] [ 5 10 15 20] [25 30 35 40] [10 15 20 25] [30 35 40 45] [15 20 25 30] [20 25 30 35] [25 30 35 40] [30 35 40 45] [ 5 10 15 20] "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMiHtGqhqECz",
        "outputId": "1842d059-b042-4129-da68-ab731761dfdf"
      },
      "source": [
        "def sub_to_batch(sub):\n",
        "  return sub.batch(window_size, drop_remainder=True)\n",
        "\n",
        "for example in windows.flat_map(sub_to_batch).take(5):\n",
        "  print(example.numpy())"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  5 10 15]\n",
            " [20 25 30 35]\n",
            " [ 5 10 15 20]\n",
            " [25 30 35 40]\n",
            " [10 15 20 25]\n",
            " [30 35 40 45]\n",
            " [15 20 25 30]\n",
            " [20 25 30 35]\n",
            " [25 30 35 40]\n",
            " [30 35 40 45]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpviclH0ssNU"
      },
      "source": [
        "ran_ds=tf.data.Dataset.range(500)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB677EwYrSYd"
      },
      "source": [
        "def make_window_dataset(ds, window_size=5, shift=1, stride=1):\n",
        "  windows = ds.window(window_size, shift=shift, stride=stride)\n",
        "  windows = windows.flat_map(sub_to_batch)\n",
        "  return windows"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bMoQCO_rSjY",
        "outputId": "3d73a481-36e4-4e7e-c794-c56960734297"
      },
      "source": [
        "ds = make_window_dataset(ran_ds, window_size=10, shift = 2, stride=3)\n",
        "\n",
        "for example in ds.take(10):\n",
        "  print(example.numpy())"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  3  6  9 12 15 18 21 24 27]\n",
            "[ 2  5  8 11 14 17 20 23 26 29]\n",
            "[ 4  7 10 13 16 19 22 25 28 31]\n",
            "[ 6  9 12 15 18 21 24 27 30 33]\n",
            "[ 8 11 14 17 20 23 26 29 32 35]\n",
            "[10 13 16 19 22 25 28 31 34 37]\n",
            "[12 15 18 21 24 27 30 33 36 39]\n",
            "[14 17 20 23 26 29 32 35 38 41]\n",
            "[16 19 22 25 28 31 34 37 40 43]\n",
            "[18 21 24 27 30 33 36 39 42 45]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIHeJGDlrSta",
        "outputId": "1f986887-3f85-4277-d41b-62becbff5433"
      },
      "source": [
        "dense_labels_ds = ds.map(dense_1_step)\n",
        "\n",
        "for inputs,labels in dense_labels_ds.take(3):\n",
        "  print(inputs.numpy(), \"=>\", labels.numpy())"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  3  6  9 12 15 18 21] => [ 9 12 15 18 21 24 27]\n",
            "[ 2  5  8 11 14 17 20 23] => [11 14 17 20 23 26 29]\n",
            "[ 4  7 10 13 16 19 22 25] => [13 16 19 22 25 28 31]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}